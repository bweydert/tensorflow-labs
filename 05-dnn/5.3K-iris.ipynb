{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import datetime\n",
    "from tensorflow.python.keras.utils import to_categorical\n",
    "from tensorflow.python.keras.callbacks import TensorBoard\n",
    "\n",
    "\n",
    "IRIS_URL = \"https://s3.amazonaws.com/elephantscale-public/data/iris/keras/iris.csv\"\n",
    "\n",
    "dataset = pd.read_csv(IRIS_URL)\n",
    "dataset.columns = ['SepalLengthCm', 'SepalWidthCm', 'PetalLengthCm', 'PetalWidthCm','Species']\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install the package for running tensorboard on google colaboration\n",
    "try:\n",
    "    import google.colab\n",
    "    IN_COLAB = True\n",
    "except:\n",
    "    IN_COLAB = False\n",
    "if IN_COLAB == True:\n",
    "    from tensorboardcolab import *\n",
    "    !pip install -U tensorboardcolab\n",
    "    !pip install -q tf-nightly-2.0-preview\n",
    "# Load the TensorBoard notebook extension\n",
    "    %load_ext tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Iris classification problem\n",
    "\n",
    "Imagine you are a botanist seeking an automated way to categorize each Iris flower you find. Machine learning provides many algorithms to statistically classify flowers. For instance, a sophisticated machine learning program could classify flowers based on photographs. Our ambitions are more modestâ€”we're going to classify Iris flowers based on the length and width measurements of their [sepals](https://en.wikipedia.org/wiki/Sepal) and [petals](https://en.wikipedia.org/wiki/Petal).\n",
    "\n",
    "The Iris genus entails about 300 species, but our program will only classify the following three:\n",
    "\n",
    "* Iris setosa\n",
    "* Iris virginica\n",
    "* Iris versicolor\n",
    "\n",
    "<table>\n",
    "  <tr><td>\n",
    "    <img src=\"https://www.tensorflow.org/images/iris_three_species.jpg\"\n",
    "         alt=\"Petal geometry compared for three iris species: Iris setosa, Iris virginica, and Iris versicolor\">\n",
    "  </td></tr>\n",
    "  <tr><td align=\"center\">\n",
    "    <b>Figure 1.</b> <a href=\"https://commons.wikimedia.org/w/index.php?curid=170298\">Iris setosa</a> (by <a href=\"https://commons.wikimedia.org/wiki/User:Radomil\">Radomil</a>, CC BY-SA 3.0), <a href=\"https://commons.wikimedia.org/w/index.php?curid=248095\">Iris versicolor</a>, (by <a href=\"https://commons.wikimedia.org/wiki/User:Dlanglois\">Dlanglois</a>, CC BY-SA 3.0), and <a href=\"https://www.flickr.com/photos/33397993@N05/3352169862\">Iris virginica</a> (by <a href=\"https://www.flickr.com/photos/33397993@N05\">Frank Mayfield</a>, CC BY-SA 2.0).<br/>&nbsp;\n",
    "  </td></tr>\n",
    "</table>\n",
    "\n",
    "Fortunately, someone has already created a [data set of 120 Iris flowers](https://en.wikipedia.org/wiki/Iris_flower_data_set) with the sepal and p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Plotting the pairwise relationship of different parameters\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set(style=\"ticks\")\n",
    "sns.set_palette(\"husl\")\n",
    "sns.pairplot(dataset,hue=\"Species\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting the data into training and test test\n",
    "X = dataset.iloc[:,0:3].values\n",
    "y = dataset.iloc[:,4].values\n",
    "\n",
    "\n",
    "n_features = X.shape[1]\n",
    "n_classes = 3\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "encoder =  LabelEncoder()\n",
    "y1 = encoder.fit_transform(y)\n",
    "\n",
    "Y = pd.get_dummies(y1).values\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test, Y_train,Y_test = train_test_split(X,Y,test_size=0.2,random_state=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In order to ignore FutureWarning\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import Dense, Dropout, Activation\n",
    "\n",
    "def create_custom_model(input_dim, output_dim, nodes, n=1, name='model'):\n",
    "    def create_model():\n",
    "        # Create model\n",
    "        model = Sequential(name=name)\n",
    "        for i in range(n):\n",
    "            model.add(Dense(nodes, input_dim=input_dim, activation='relu'))\n",
    "        model.add(Dense(output_dim, activation='softmax'))\n",
    "\n",
    "        # Compile model\n",
    "        model.compile(loss='categorical_crossentropy', \n",
    "                      optimizer='adam', \n",
    "                      metrics=['accuracy'])\n",
    "        return model\n",
    "    return create_model\n",
    "\n",
    "models = [create_custom_model(n_features, n_classes, 8, i, 'model_{}'.format(i)) \n",
    "          for i in range(1, 4)]\n",
    "\n",
    "for create_model in models:\n",
    "    create_model().summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_dict = {}\n",
    "\n",
    "# TensorBoard Callback\n",
    "\n",
    "if IN_COLAB == True:\n",
    "    log_dir=\"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=0)\n",
    "    for create_model in models:\n",
    "        model = create_model()\n",
    "        print('Model name:', model.name)\n",
    "        history_callback = model.fit(X_train, Y_train,\n",
    "                                 batch_size=5,\n",
    "                                 epochs=50,\n",
    "                                 verbose=0,\n",
    "                                 validation_data=(X_test, Y_test),\n",
    "                                 callbacks=[tensorboard_callback])\n",
    "        score = model.evaluate(X_test, Y_test, verbose=0)\n",
    "        print('Test loss:', score[0])\n",
    "        print('Test accuracy:', score[1])\n",
    "        history_dict[model.name] = [history_callback, model]\n",
    "        \n",
    "else:\n",
    "    cb = TensorBoard(log_dir='/tmp/tensorflow_logs/example', histogram_freq=0)\n",
    "    for create_model in models:\n",
    "        model = create_model()\n",
    "        print('Model name:', model.name)\n",
    "        history_callback = model.fit(X_train, Y_train,\n",
    "                                 batch_size=5,\n",
    "                                 epochs=50,\n",
    "                                 verbose=0,\n",
    "                                 validation_data=(X_test, Y_test),\n",
    "                                 callbacks=[cb])\n",
    "        score = model.evaluate(X_test, Y_test, verbose=0)\n",
    "        print('Test loss:', score[0])\n",
    "        print('Test accuracy:', score[1])\n",
    "        history_dict[model.name] = [history_callback, model]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(2, figsize=(8, 6))\n",
    "\n",
    "for model_name in history_dict:\n",
    "    val_acc = history_dict[model_name][0].history['val_acc']\n",
    "    val_loss = history_dict[model_name][0].history['val_loss']\n",
    "    ax1.plot(val_acc, label=model_name)\n",
    "    ax2.plot(val_loss, label=model_name)\n",
    "    \n",
    "ax1.set_ylabel('validation accuracy')\n",
    "ax2.set_ylabel('validation loss')\n",
    "ax2.set_xlabel('epochs')\n",
    "ax1.legend()\n",
    "ax2.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot ROC Curve\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "\n",
    "for model_name in history_dict:\n",
    "    model = history_dict[model_name][1]\n",
    "    \n",
    "    Y_pred = model.predict(X_test)\n",
    "    fpr, tpr, threshold = roc_curve(Y_test.ravel(), Y_pred.ravel())\n",
    "    \n",
    "    plt.plot(fpr, tpr, label='{}, AUC = {:.3f}'.format(model_name, auc(fpr, tpr)))\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.title('ROC curve')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Perform K-Fold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "create_model = create_custom_model(n_features, n_classes, 8, 3)\n",
    "\n",
    "estimator = KerasClassifier(build_fn=create_model, epochs=100, batch_size=5, verbose=0)\n",
    "scores = cross_val_score(estimator, X, Y, cv=10)\n",
    "print(\"Accuracy : {:0.2f} (+/- {:0.2f})\".format(scores.mean(), scores.std()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we run the TensorBaord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Automatic loading of tensorboard in Colab\n",
    "if IN_COLAB:\n",
    "    %tensorboard --logdir logs/fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Local:\n",
    "\n",
    "Now run the following command on a bash\n",
    "\n",
    "```bash\n",
    "$ tensorboard --logdir=/tmp/tensorflow_logs\n",
    "```\n",
    "Then open the browser(Chrome) and insert this address\n",
    "\n",
    "```bash\n",
    "localhost:6006\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
