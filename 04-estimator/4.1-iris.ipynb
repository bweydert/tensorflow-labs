{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tfox/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import urllib\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "IRIS_TRAINING = \"../data/iris/iris_training.csv\"\n",
    "IRIS_TRAINING_URL = \"http://download.tensorflow.org/data/iris_training.csv\"\n",
    "\n",
    "IRIS_TEST = \"../data/iris/iris_test.csv\"\n",
    "IRIS_TEST_URL = \"http://download.tensorflow.org/data/iris_test.csv\"\n",
    "\n",
    "CSV_COLUMN_NAMES = ['SepalLength', 'SepalWidth',\n",
    "                    'PetalLength', 'PetalWidth', 'Species']\n",
    "\n",
    "SPECIES = ['Setosa', 'Versicolor', 'Virginica']\n",
    "\n",
    "BATCH_SIZE=10\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_data(y_name='Species'):\n",
    "    \"\"\"Returns the iris dataset as (train_x, train_y), (test_x, test_y).\"\"\"\n",
    "   \n",
    "    train = pd.read_csv(IRIS_TRAINING, names=CSV_COLUMN_NAMES, header=0)\n",
    "    train_x, train_y = train, train.pop(y_name)\n",
    "\n",
    "    test = pd.read_csv(IRIS_TEST, names=CSV_COLUMN_NAMES, header=0)\n",
    "    test_x, test_y = test, test.pop(y_name)\n",
    "\n",
    "    return (train_x, train_y, test_x, test_y)\n",
    "\n",
    "train_x, train_y, test_x, test_y = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify that all features have real-value data\n",
    "feature_columns = []\n",
    "for key in train_x.keys():\n",
    "    feature_columns.append(tf.feature_column.numeric_column(key=key))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/tmp/iris_model', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0xb2dea3940>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Build 3 layer DNN with 10, 20, 10 units respectively.\n",
    "classifier = tf.estimator.DNNClassifier(feature_columns=feature_columns,\n",
    "                                            hidden_units=[10, 20, 10],\n",
    "                                            n_classes=3,\n",
    "                                            model_dir=\"/tmp/iris_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into /tmp/iris_model/model.ckpt.\n",
      "INFO:tensorflow:loss = 15.610294, step = 1\n",
      "INFO:tensorflow:global_step/sec: 578.851\n",
      "INFO:tensorflow:loss = 4.180154, step = 101 (0.174 sec)\n",
      "INFO:tensorflow:global_step/sec: 904.313\n",
      "INFO:tensorflow:loss = 1.0358124, step = 201 (0.111 sec)\n",
      "INFO:tensorflow:global_step/sec: 787.602\n",
      "INFO:tensorflow:loss = 0.20880494, step = 301 (0.127 sec)\n",
      "INFO:tensorflow:global_step/sec: 828.498\n",
      "INFO:tensorflow:loss = 0.058251597, step = 401 (0.120 sec)\n",
      "INFO:tensorflow:global_step/sec: 956.464\n",
      "INFO:tensorflow:loss = 0.31146997, step = 501 (0.105 sec)\n",
      "INFO:tensorflow:global_step/sec: 965.213\n",
      "INFO:tensorflow:loss = 0.08877989, step = 601 (0.104 sec)\n",
      "INFO:tensorflow:global_step/sec: 1028.72\n",
      "INFO:tensorflow:loss = 0.049182408, step = 701 (0.097 sec)\n",
      "INFO:tensorflow:global_step/sec: 931.55\n",
      "INFO:tensorflow:loss = 4.448159, step = 801 (0.107 sec)\n",
      "INFO:tensorflow:global_step/sec: 1077.39\n",
      "INFO:tensorflow:loss = 0.027826572, step = 901 (0.093 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1000 into /tmp/iris_model/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.2660581.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.estimator.canned.dnn.DNNClassifier at 0xb2dea3a58>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the input function\n",
    "\n",
    "def train_input_fn(features, labels, batch_size):\n",
    "    \"\"\"An input function for training\"\"\"\n",
    "    # Convert the inputs to a Dataset.\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((dict(features), labels))\n",
    "\n",
    "    # Shuffle, repeat, and batch the examples.\n",
    "    dataset = dataset.shuffle(1000).repeat().batch(batch_size)\n",
    "\n",
    "    # Return the dataset.\n",
    "    return dataset\n",
    "\n",
    "# Fit model.\n",
    "# Train the Model.\n",
    "classifier.train(\n",
    "    input_fn=lambda:train_input_fn(train_x, train_y, BATCH_SIZE), steps=1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-01-22-04:49:08\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/iris_model/model.ckpt-1000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2019-01-22-04:49:09\n",
      "INFO:tensorflow:Saving dict for global step 1000: accuracy = 0.96666664, average_loss = 0.065629, global_step = 1000, loss = 0.65629\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 1000: /tmp/iris_model/model.ckpt-1000\n",
      "\n",
      "Test set accuracy: 0.967\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def eval_input_fn(features, labels, batch_size):\n",
    "    \"\"\"An input function for evaluation or prediction\"\"\"\n",
    "    \n",
    "    features=dict(features)\n",
    "    inputs = features if labels is None else (features, labels)\n",
    "   \n",
    "    # Convert the inputs to a Dataset.\n",
    "    return tf.data.Dataset.from_tensor_slices(inputs).batch(batch_size)\n",
    "\n",
    "\n",
    "# Evaluate the model.\n",
    "eval_result = classifier.evaluate(\n",
    "    input_fn=lambda:eval_input_fn(test_x, test_y, BATCH_SIZE))\n",
    "\n",
    "print('\\nTest set accuracy: {accuracy:0.3f}\\n'.format(**eval_result))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/iris_model/model.ckpt-1000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'logits': array([  1.1274962,  -6.0248094, -13.965336 ], dtype=float32),\n",
       "  'probabilities': array([9.9921727e-01, 7.8244368e-04, 2.7856464e-07], dtype=float32),\n",
       "  'class_ids': array([0]),\n",
       "  'classes': array([b'0'], dtype=object)},\n",
       " {'logits': array([-6.6753   ,  1.2756677, -4.7903156], dtype=float32),\n",
       "  'probabilities': array([3.5138187e-04, 9.9733436e-01, 2.3142896e-03], dtype=float32),\n",
       "  'class_ids': array([1]),\n",
       "  'classes': array([b'1'], dtype=object)},\n",
       " {'logits': array([-11.39478   ,  -0.42954504,   3.3908927 ], dtype=float32),\n",
       "  'probabilities': array([3.7089200e-07, 2.1448089e-02, 9.7855157e-01], dtype=float32),\n",
       "  'class_ids': array([2]),\n",
       "  'classes': array([b'2'], dtype=object)}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate predictions from the model\n",
    "expected = ['Setosa', 'Versicolor', 'Virginica']\n",
    "predict_x = {\n",
    "    'SepalLength': [5.1, 5.9, 6.9],\n",
    "    'SepalWidth': [3.3, 3.0, 3.1],\n",
    "    'PetalLength': [1.7, 4.2, 5.4],\n",
    "    'PetalWidth': [0.5, 1.5, 2.1],\n",
    "}\n",
    "\n",
    "predictions = classifier.predict(\n",
    "    input_fn=lambda:eval_input_fn(predict_x, test_y[:3], batch_size=BATCH_SIZE))\n",
    "\n",
    "list(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
