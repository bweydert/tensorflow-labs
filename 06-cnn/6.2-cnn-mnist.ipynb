{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 6.2: MNIST in CNN\n",
    "\n",
    "This lab uses the low-level TF API to perform MNIST using CNNs. We will compare the results with our previous model whhich did not use Convolutional Layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: The Low-Level API\n",
    "\n",
    "Lots of Bookkeeping!  Notice that we are having to keep track of all of the sizes of inputs and outputs, requires you to whip out your calculator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from IPython.display import Image\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install the package for running tensorboard on google colaboration\n",
    "try:\n",
    "    import google.colab\n",
    "    IN_COLAB = True\n",
    "except:\n",
    "    IN_COLAB = False\n",
    "if IN_COLAB == True:\n",
    "    !pip install -U tensorboardcolab\n",
    "    from tensorboardcolab import *\n",
    "    tbc=TensorBoardColab()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "#Load Mnist data\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Amir\\AppData\\Local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Bias:0' shape=() dtype=string>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Define Variable placeholders\n",
    "\n",
    "x = tf.placeholder(tf.float32, [None, 784])\n",
    "W = tf.Variable(tf.zeros([784, 10]))\n",
    "b = tf.Variable(tf.zeros([10]))\n",
    "y_ = tf.placeholder(tf.float32, [None, 10])\n",
    "\n",
    "# Add summaries to collect information needed for tensorboard\n",
    "tf.summary.histogram(\"Weight\", W)\n",
    "tf.summary.histogram(\"Bias\", b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weight_variable(shape):\n",
    "  initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "  return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape):\n",
    "  initial = tf.constant(0.1, shape=shape)\n",
    "  return tf.Variable(initial)\n",
    "\n",
    "def conv2d(x, W):\n",
    "  return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "def max_pool_2x2(x):\n",
    "  return tf.nn.max_pool(x, ksize=[1, 2, 2, 1],\n",
    "                        strides=[1, 2, 2, 1], padding='SAME')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Picture of the Architecture:\n",
    "\n",
    "![Illustration of the Model](https://s3.amazonaws.com/elephantscale-public/labs/images/tensorflow-labs/lenet-architecture.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Bias_conv1:0' shape=() dtype=string>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First Convolutional Layer\n",
    "W_conv1 = weight_variable([5, 5, 1, 32])\n",
    "b_conv1 = bias_variable([32])\n",
    "\n",
    "x_image = tf.reshape(x, [-1,28,28,1])\n",
    "\n",
    "h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1)\n",
    "h_pool1 = max_pool_2x2(h_conv1)\n",
    "\n",
    "# Add summaries to collect information needed for tensorboard\n",
    "tf.summary.histogram(\"Weight_conv1\", W_conv1)\n",
    "tf.summary.histogram(\"Bias_conv1\", b_conv1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Bias_conv2:0' shape=() dtype=string>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Second Convolutional Layer\n",
    "\n",
    "W_conv2 = weight_variable([5, 5, 32, 64])\n",
    "b_conv2 = bias_variable([64])\n",
    "\n",
    "h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)\n",
    "h_pool2 = max_pool_2x2(h_conv2)\n",
    "\n",
    "# Add summaries to collect information needed for tensorboard\n",
    "tf.summary.histogram(\"Weight_conv2\", W_conv2)\n",
    "tf.summary.histogram(\"Bias_conv2\", b_conv2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Bias_fc1:0' shape=() dtype=string>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Densely Connected Layer\n",
    "\n",
    "W_fc1 = weight_variable([7 * 7 * 64, 1024])\n",
    "b_fc1 = bias_variable([1024])\n",
    "\n",
    "h_pool2_flat = tf.reshape(h_pool2, [-1, 7*7*64])\n",
    "h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)\n",
    "\n",
    "# Add summaries to collect information needed for tensorboard\n",
    "tf.summary.histogram(\"Weight_fc1\", W_fc1)\n",
    "tf.summary.histogram(\"Bias_fc1\", b_fc1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-9-30bc8c76b9f5>:4: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "# Dropout To Reduce Overfitting\n",
    "\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Readout Layer\n",
    "\n",
    "W_fc2 = weight_variable([1024, 10])\n",
    "b_fc2 = bias_variable([10])\n",
    "\n",
    "y_conv = tf.matmul(h_fc1_drop, W_fc2) + b_fc2\n",
    "\n",
    "tf.summary.histogram(\"Weight_fc2\", W_fc2)\n",
    "tf.summary.histogram(\"Bias_fc2\", b_fc2)\n",
    "merge=tf.summary.merge_all()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0, training accuracy 0.08\n",
      "step 100, training accuracy 0.08\n",
      "step 200, training accuracy 0.08\n",
      "step 300, training accuracy 0.12\n",
      "step 400, training accuracy 0\n",
      "step 500, training accuracy 0.12\n",
      "step 600, training accuracy 0.16\n",
      "step 700, training accuracy 0.14\n",
      "step 800, training accuracy 0.16\n",
      "step 900, training accuracy 0.16\n",
      "step 1000, training accuracy 0.22\n",
      "step 1100, training accuracy 0.28\n",
      "step 1200, training accuracy 0.32\n",
      "step 1300, training accuracy 0.16\n",
      "step 1400, training accuracy 0.3\n",
      "step 1500, training accuracy 0.48\n",
      "step 1600, training accuracy 0.48\n",
      "step 1700, training accuracy 0.38\n",
      "step 1800, training accuracy 0.34\n",
      "step 1900, training accuracy 0.38\n",
      "test accuracy 0.4462\n"
     ]
    }
   ],
   "source": [
    "# Train Model\n",
    "logs_path = '/tmp/tensorflow_logs/example/' #path for writing Tensorboard logs \n",
    "cross_entropy = tf.reduce_mean(\n",
    "    tf.nn.softmax_cross_entropy_with_logits_v2(labels=y_, logits=y_conv))\n",
    "train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n",
    "correct_prediction = tf.equal(tf.argmax(y_conv,1), tf.argmax(y_,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "sess = tf.InteractiveSession()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "summary_writer = tf.summary.FileWriter(logs_path, graph=tf.get_default_graph()) #write the logs \n",
    "\n",
    "for i in range(2000):\n",
    "    batch = mnist.train.next_batch(50)\n",
    "    if i%100 == 0:\n",
    "        train_accuracy = accuracy.eval(feed_dict={\n",
    "            x:batch[0], y_: batch[1], keep_prob: 1.0})\n",
    "        print(\"step %d, training accuracy %g\"%(i, train_accuracy))\n",
    "        train_step.run(feed_dict={x: batch[0], y_: batch[1], keep_prob: 0.5})\n",
    "        summary = sess.run(merge )\n",
    "        summary_writer.add_summary(summary, i )# adding data to logs in every iteration in local path\n",
    "        \n",
    "        # adding data to logs in every iteration on google colab\n",
    "        if IN_COLAB == True:\n",
    "            summary_writer = tbc.get_writer()# saving data on google colab\n",
    "            summary_writer.add_graph(sess.graph)\n",
    "\n",
    "\n",
    "print(\"test accuracy %g\"%accuracy.eval(feed_dict={\n",
    "    x: mnist.test.images, y_: mnist.test.labels, keep_prob: 1.0}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we run the TensorBaord\n",
    "#### Local:\n",
    "\n",
    "Now run the following command on a bash\n",
    "\n",
    "```bash\n",
    "$ tensorboard --logdir=/tmp/tensorflow_logs\n",
    "```\n",
    "Then open the browser(Chrome) and insert this address\n",
    "\n",
    "```bash\n",
    "localhost:6006\n",
    "```\n",
    "\n",
    "#### Google colab\n",
    "\n",
    "\n",
    "\n",
    "Click on the link you had got at the first step\n",
    "\n",
    "![](../images/tb_colab.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: The tf.keras High Level API\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Amir\\AppData\\Local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\Amir\\AppData\\Local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 48s 805us/sample - loss: 0.2193 - acc: 0.9352 - val_loss: 0.0967 - val_acc: 0.9706\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 47s 789us/sample - loss: 0.0972 - acc: 0.9709 - val_loss: 0.0780 - val_acc: 0.9749\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 48s 801us/sample - loss: 0.0688 - acc: 0.9779 - val_loss: 0.0702 - val_acc: 0.9778\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 48s 793us/sample - loss: 0.0521 - acc: 0.9833 - val_loss: 0.0794 - val_acc: 0.9761\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 48s 797us/sample - loss: 0.0427 - acc: 0.9859 - val_loss: 0.0590 - val_acc: 0.9826\n",
      "10000/10000 [==============================] - 1s 120us/sample - loss: 0.0590 - acc: 0.9826\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.05903689107330283, 0.9826]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import datetime\n",
    "from tensorflow.python.keras.callbacks import TensorBoard\n",
    "%matplotlib inline\n",
    "tf.summary.FileWriterCache.clear()\n",
    "\n",
    "# Install the packages and importing libraries for running tensorboard on google colaboration\n",
    "try:\n",
    "    import google.colab\n",
    "    IN_COLAB = True\n",
    "except:\n",
    "    IN_COLAB = False\n",
    "if IN_COLAB == True:\n",
    "    from tensorboardcolab import *\n",
    "    !pip install -U tensorboardcolab\n",
    "    !pip install -q tf-nightly-2.0-preview\n",
    "# Load the TensorBoard notebook extension\n",
    "    %load_ext tensorboard\n",
    "    from tensorboardcolab import *\n",
    "\n",
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "(x_train, y_train),(x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0  # Standardize to unit norm 0.0 to 1.0\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "  tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
    "  tf.keras.layers.Dropout(0.2),\n",
    "  tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "if IN_COLAB == True:\n",
    "    log_dir=\"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "    model.fit(x_train, y_train, epochs=5,validation_data=(x_test, y_test), callbacks=[tensorboard_callback])\n",
    "else:\n",
    "    tensorboard = TensorBoard(log_dir='/tmp/tensorflow_logs/example', histogram_freq=1)\n",
    "    model.fit(x_train, y_train, epochs=5,validation_data=(x_test, y_test), callbacks=[tensorboard])\n",
    "\n",
    "model.evaluate(x_test, y_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we run the TensorBaord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Automatic loading of tensorboard in Colab\n",
    "if IN_COLAB:\n",
    "    %tensorboard --logdir logs/fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Local:\n",
    "\n",
    "Now run the following command on a bash\n",
    "\n",
    "```bash\n",
    "$ tensorboard --logdir=/tmp/tensorflow_logs\n",
    "```\n",
    "Then open the browser(Chrome) and insert this address\n",
    "\n",
    "```bash\n",
    "localhost:6006\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
