{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 4.2K: Training Linear Model with Keras API for MNIST Dataset\n",
    "\n",
    "In this lab we we will use the Keras API for the MNIST Dataset on a Linear Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import datetime\n",
    "from IPython.display import Image\n",
    "from tensorflow.python.keras.callbacks import TensorBoard\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install the package for running tensorboard on google colaboration\n",
    "try:\n",
    "    import google.colab\n",
    "    IN_COLAB = True\n",
    "except:\n",
    "    IN_COLAB = False\n",
    "if IN_COLAB == True:\n",
    "    from tensorboardcolab import *\n",
    "    !pip install -U tensorboardcolab\n",
    "    !pip install -q tf-nightly-2.0-preview\n",
    "# Load the TensorBoard notebook extension\n",
    "    %load_ext tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Load MNIST Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "(x_train, y_train),(x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0  # Standardize to unit norm 0.0 to 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Define the Model\n",
    "\n",
    "The model has an input layer, zero hidden layers, and an output layer.\n",
    "\n",
    "Layers:\n",
    "\n",
    " * Input Layer: Implemented with `Flatten`. Takes the 28 x 28 image and creates a 1 x 784 vector as input.\n",
    " * Output Layer: Implemented with `Dense`. Has 10 neurons as output, because of 10 classes. Uses softmax activation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Amir\\AppData\\Local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Flatten(input_shape=(28, 28)), # 784 inputs\n",
    "  tf.keras.layers.Dense(10, activation=tf.nn.softmax) # 10 outputs\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Compile the Model\n",
    "    \n",
    "In `tf.keras` the model should be compiled.  We need to define the following:\n",
    "\n",
    "* optimzer used (in this case Adam Optimzation) \n",
    "* the loss function. categorical cross entropy in this case\n",
    "* Metric(s), Accuracy here. This will be used for cross validation.\n",
    "\n",
    "Note that training will NOT occur until we call `model.fit()`\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Train (Fit) the Model\n",
    "\n",
    "Here we will fit the model with our X and Y values. \n",
    "\n",
    "**TODO** Enter 5 for the number of Epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 4s 71us/sample - loss: 0.4674 - acc: 0.8781 - val_loss: 0.3074 - val_acc: 0.9136\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 4s 64us/sample - loss: 0.3032 - acc: 0.9147 - val_loss: 0.2798 - val_acc: 0.9219\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 4s 61us/sample - loss: 0.2829 - acc: 0.9209 - val_loss: 0.2748 - val_acc: 0.9248\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 4s 59us/sample - loss: 0.2727 - acc: 0.9241 - val_loss: 0.2651 - val_acc: 0.9260\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 4s 66us/sample - loss: 0.2662 - acc: 0.9259 - val_loss: 0.2686 - val_acc: 0.9255\n"
     ]
    }
   ],
   "source": [
    "if IN_COLAB == True:\n",
    "    log_dir=\"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "    model.fit(x_train, y_train, epochs=5,validation_data=(x_test, y_test), callbacks=[tensorboard_callback])\n",
    "else:\n",
    "    tensorboard = TensorBoard(log_dir='/tmp/tensorflow_logs/example', histogram_freq=1)\n",
    "    model.fit(x_train, y_train, epochs=5,validation_data=(x_test, y_test), callbacks=[tensorboard])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Step 5: Evaluate the Model\n",
    "\n",
    "Here we will evaluate the model. Accuracy is the Metric Used.\n",
    "\n",
    "Note that training validation accuracy is considerably better than the test accuracy. This may indicate some overfitting has occurred."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 35us/sample - loss: 0.2686 - acc: 0.9255\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.26864535204172135, 0.9255]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Automatic loading of tensorboard in Colab\n",
    "if IN_COLAB:\n",
    "    %tensorboard --logdir logs/fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we run the TensorBaord\n",
    "#### Local:\n",
    "\n",
    "Now run the following command on a bash\n",
    "\n",
    "```bash\n",
    "$ tensorboard --logdir=/tmp/tensorflow_logs\n",
    "```\n",
    "Then open the browser(Chrome) and insert this address\n",
    "\n",
    "```bash\n",
    "localhost:6006\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
