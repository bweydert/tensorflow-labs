{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab: TXT-2: N-grams\n",
    "\n",
    "## Overview\n",
    "Process N-grams\n",
    "\n",
    "## Run time \n",
    "20 min"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from os.path import expanduser\n",
    "nltk.data.path.append( expanduser(\"~\") + \"/data/nltk_data\")\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "text = \"\"\"It was a sunny day! We went to the dog park.  Lots of dogs were running around.  \n",
    "My dog likes to run too; so he had a great time.  \n",
    "I bought ice cream from the ice cream truck. Yummy!\n",
    "It was a perfect sunny day!\"\"\"\n",
    "\n",
    "words = word_tokenize(text)\n",
    "words_lower = [i.lower() for i in words]\n",
    "\n",
    "print (\"raw text (\", len(text) , \") : \\n\", text)\n",
    "print (\"---\")\n",
    "print (\"words (\" , len(words), \") : \\n\",words)\n",
    "print (\"---\")\n",
    "\n",
    "bigrams = nltk.ngrams(words, 2)\n",
    "fdist = nltk.FreqDist(bigrams)\n",
    "print(\"bigrams in raw text :\\n\", fdist.most_common())\n",
    "print (\"---\")\n",
    "\n",
    "\n",
    "## TODO : Now cleanup STOP words and calculate bigrams again\n",
    "\n",
    "stop_words_english = set(stopwords.words('english'))\n",
    "stop_words_english.update(['-', '.', ',', '#', '\"', \"'\", '?', '!', ':', ';', '(', ')', '[', ']', '{', '}']) \n",
    "\n",
    "cleaned = [i for i in words_lower if i not in stop_words_english]\n",
    "print (\"cleaned words (\", len(cleaned), \"):\\n\", cleaned)\n",
    "print (\"---\")\n",
    "\n",
    "## Complete the following\n",
    "bigrams = nltk.ngrams(???, ???)\n",
    "fdist = nltk.FreqDist(???)\n",
    "print(\"bigrams in cleaned text:\\n\", fdist.most_common())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2 - Find top bigrams of following text\n",
    "\n",
    "State of The Union - location : ../data/text/sotu-2014-obama.txt\n",
    "Moby Dick : ../data/text/moby-dick.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# read the text as follows\n",
    "f = open('../data/text/sotu-2014-obama.txt')\n",
    "text = f.read()\n",
    "\n",
    "# TODO - continue from here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
